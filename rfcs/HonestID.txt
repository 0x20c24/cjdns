Node ID Honesty - Request for Comments

Please direct comments at:
#dns-p2p on efnet
#cjdns on efnet
#bittorrent on freenode
cjd on efnet
calebdelisle [at) lav@bit dot c0m

This proposed protocol attempts to offer DHT nodes the means to prove to each other that they chose their
IDs randomly. Furthermore it attempts to offer mobility and resist IP address spoofing attacks by avoiding
reliance on the integrity of the IP network for confidence. A side effect is that this protocol provides
confidentiality and integrity of DHT communications.

Creating a node ID:
  The node will generate a public/private key pair using the curve25519 algorithm.
  The low 160 bits of the public key will be used as the node id. The remaining 96 bits will be referred to
  as the "key prefix" it is needed in order to authenticate messages from a node and thus must be passed in
  find_node and get_peers responses.
  TODO: Understand whether curve25519 public keys will be random enough to satisfy requirements for the 
        DHT protocol.

When Alice asks Bob for directions to Zack, Bob predictably provides the node IDs and IP addresses of 8 
nodes who he knows and are closest to Zack. Bob must also provide the key prefixes of those of the nodes who
support Honest ID.

Bob sends Alice a typical "find_node" or "get_peers" response except an extra key is added to the table:
{
  "t":"aa",
  "y":"r",
  "r": {
    "id":"0123456789abcdefghij",
    "nodes": "<Charlie'sID+IPAddr:port><Dave'sId+IpAddr:port><Elinor'sId+IpAddr:port>..."
    "hi": "<bitmask><Charlie'sKeyPrefix><Elinor'sKeyPrefix>"
  }
}
The "hi" key looks up a string and the first byte in the string is a bitmask. Since no more than 8 nodes are
ever sent, the bitmask will tell Alice which nodes the key prefixes belong to. If Bob sends 3 nodes, where
nodes one and three support Honest ID and number two doesn't, the bitmask would read 10100000 and the
key prefixes would be in the same order as the nodes.

When Alice wants to send a message to one of the nodes who we will call Charlie, Alice
composes her message and enciphers it with a secret generated from her private key, Charlie's public key,
and an 8 byte nounce. Alice derives Charlie's public key from Charlie's key prefix and node id as provided
by Bob, then she prepends her public key and finally prepends a single byte null pad.

[0x00][Alice's Public key][nounce][Alice+Charlie crypto-authed message]

When Charlie receives the message, he determines that it is encrypted by the first byte being null.
He then reads the next 32 bytes as Alice's public key and generates a shared secret using it and his
private key. Then he reads the next 8 bytes as a nounce and using the secret and nounce to decipher the 
message. He tags the message with the low 160 bits of Alice's public key as her node id. It is critical
that after the message is fed through the bencoding engine, the message is modified by inserting or
overwriting any node id which Alice may have sent lest Alice encrypt with one ID and insert another in
the message. Since Alice has sent Charlie a valid message, he can be confident that she is honest about
her node id and if she is in his routing table, her entry must be modified to include her key prefix and
the fact that she is known honest.

After handling the message and crafting his reply, Charlie sends his response with the same encoding.

[0x00][Charlie's Public key][nounce][Alice+Charlie crypto-authed message]

After receiving the response, Alice decodes it using the same protocol and now knows that Charlie is
honest because he was able to generate the response.

Packet size overhead:
Although this protocol modification prepends a significant amount of data to each message, packet overhead
is minimal. There is a null byte, a 32 byte public key, and an 8 byte nounce comprising a whopping 41 bytes
but since the receiving party must set the node id in the message to insure integrity, the sending party
may safely omit it. A node id is made of "2id:20" + 20 bytes of id, a total of 27 bytes. Omitting this entry
brings the total overhead down to a measly 14 bytes.
By far the greatest overhead will be in "find_node" and "get_peers" requests which will incur an additional
worst case 96 bytes for the 12 byte key prefixes of the 8 nodes sent plus one byte for the bitmask and
7 bytes for the string key "2hi:97". This overhead is unavoidable without adding a handshake.

Processor overhead:
Curve25519 holds records for Diffie-Hellman key negotiation and in addition, nodes may store the shared
secret for peers whom they talk the most with. Because the public keys are sent with every packet, nodes
need not store anything and can handle all traffic statelessly.

About nounces:
"With an n-bit hash code, there's a roughly 39.3% chance of a collision with 2^n/2 items"
"With one million items and a perfect 64-bit hash function, the chance of getting a collision is 1 in
3.7x107â€” or roughly half as likely as winning the UK National Lottery jackpot."
See: http://www.javamex.com/tutorials/collections/strong_hash_code.shtml
Implementations may generate nounces randomly or using a counter. Any implementation which choses to use
a counter must compare the public keys of the 2 nodes as big endian integers and the node possessing the
lesser key shall count odd numbers and the node possessing the greater key shall count even numbers.
Randomly choosing nounces is acceptable and in cases where the nodes are not in the same routing table it
is expected. Clearly there is no additional risk from Alice using a counter and Charlie using random
nounces.

Enforcing the change:
Rather than simply blacklisting all nodes who do not comply after some arbitrary cutoff date, implementers
should take the more gentle approach of allowing new nodes who implement the protocol to evict old good 
nodes from buckets thus promoting the protocol rather than forcing it. It is recommended that nodes rate
limit the eviction of old good nodes lest they have their routing tables flushed by a denial of service
attack while the swarm is in transition. The rate at which old good nodes should be evicted is a topic
in need of research.
